{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import data as dt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import fair_classification.utils as ut\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import data as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores key value pairs of dataset, sensitive attributes and target labels\n",
    "DATA2D = {'adult': 'target',\n",
    "          'compas': 'ScoreText_',\n",
    "          'german': 'loan_status',\n",
    "          'synthetic' : 'D'}\n",
    "\n",
    "DATA2S = {'adult': 'sex',\n",
    "          'compas': 'Ethnic_Code_Text_',\n",
    "          'german': 'sex',\n",
    "          'synthetic': 'S'}\n",
    "\n",
    "NAMES = ['adult', 'compas', 'german', 'synthetic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read input parameters\n",
    "# debias = true represents proposed method for deriving fair label\n",
    "\n",
    "config_path = os.path.join(\"report_input.json\")\n",
    "config = None\n",
    "\n",
    "with open(config_path, 'r') as fh:\n",
    "    content = json.load(fh)\n",
    "\n",
    "\n",
    "\n",
    "dataset = content['dataset']\n",
    "exp_num = content['exp-id']\n",
    "num_X = content['num_X']\n",
    "fold = content['fold']\n",
    "debias = content['debias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, cloumns, decision_label, train_y_fair, train_y_proxy, test_y_fair, test_y_proxy , test_y_debias, train_y_debias= dt.load_data(dataset, fold, num_X=num_X, use_fair=debias, exp_num = exp_num)\n",
    "\n",
    "# train splits\n",
    "train_y = train_y_fair if debias else train_data[decision_label]\n",
    "train_X = train_data.drop(columns=cloumns)\n",
    "train_sex = train_data[DATA2S[dataset]]\n",
    "s_train = np.array(train_data[DATA2S[dataset]])\n",
    "\n",
    "# test splits\n",
    "test_X = test_data.drop(columns=cloumns)\n",
    "test_y = test_y_fair if debias else test_data[decision_label]\n",
    "s_test = np.array(test_data[DATA2S[dataset]])\n",
    "results = defaultdict(dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1: Unmitigation classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_prob = logisticRegr.predict_log_proba(train_X)\n",
    "train_pred = logisticRegr.predict(train_X)\n",
    "test_pred = logisticRegr.predict(test_X)\n",
    "test_pred_prob = logisticRegr.predict_log_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics for this prediction\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "results[\"unmitigatedLR\"][\"fair\"] = dict()\n",
    "results[\"unmitigatedLR\"][\"proxy\"] = dict()\n",
    "\n",
    "results[\"unmitigatedLR\"][\"fair\"][\"eo_diff\"] = equalized_odds_difference(test_y, test_pred, sensitive_features=s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eo difference tested against proxy labels\n",
    "results[\"unmitigatedLR\"][\"proxy\"][\"eo_diff\"] = equalized_odds_difference(test_y_proxy, test_pred, sensitive_features=s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"unmitigatedLR\"][\"fair\"][\"roc_auc\"]= roc_auc_score(test_y, test_pred )\n",
    "results[\"unmitigatedLR\"][\"fair\"][\"f1\"] = f1_score(test_y, test_pred)\n",
    "results[\"unmitigatedLR\"][\"fair\"][\"check_acc\"] = ut.check_accuracy(None, train_X, train_y, test_X, test_y, train_pred, test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# against proxy label\n",
    "\n",
    "results[\"unmitigatedLR\"][\"proxy\"][\"roc_auc\"] = roc_auc_score(test_y_proxy, test_pred )\n",
    "results[\"unmitigatedLR\"][\"proxy\"][\"f1\"] = f1_score(test_y_proxy, test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentiated gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fair_reduction as fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utils: check accuracy score\n",
      "(0.6666666666666666, 0.63, 540, 63)\n",
      "Equalized odds values:\n",
      "0.26315789473684215\n"
     ]
    }
   ],
   "source": [
    "prob_train, prob_test = fr.reduction(dataset, fold, num_X=num_X, use_debias = debias, exp_num=exp_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"reduction\"][\"proxy\"] = dict()\n",
    "results[\"reduction\"][\"fair\"] = dict()\n",
    "\n",
    "results[\"reduction\"][\"fair\"][\"roc_auc\"] = roc_auc_score(test_y, test_pred )\n",
    "results[\"reduction\"][\"fair\"][\"f1\"] = f1_score(test_y, test_pred)\n",
    "results[\"reduction\"][\"fair\"][\"check_acc\"] = ut.check_accuracy(None, train_X, train_y, test_X, test_y, train_pred, test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"reduction\"][\"proxy\"][\"roc_auc\"] = roc_auc_score(test_y_proxy, test_pred )\n",
    "results[\"reduction\"][\"proxy\"][\"f1\"] = f1_score(test_y_proxy, test_pred)\n",
    "results[\"reduction\"][\"proxy\"][\"check_acc\"] = ut.check_accuracy(None, train_X, train_y, test_X, test_y_proxy, train_pred, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"reduction\"][\"proxy\"][\"eo_diff\"] = equalized_odds_difference(test_y_proxy, np.array(test_pred > 0.5).astype(int), sensitive_features=s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"reduction\"][\"fair\"][\"eo_diff\"] = equalized_odds_difference(test_y, np.array(test_pred > 0.5).astype(int), sensitive_features=s_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fair LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fair_lr as flr\n",
    "import fair_classification.loss_funcs as lf # loss funcs that can be optimized subject to various constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV = DATA2S[dataset]\n",
    "x_control_train = {SV: s_train}\n",
    "S_test = np.array(test_data[DATA2S[dataset]])\n",
    "x_control_test = {SV: s_test}\n",
    "results[\"fairLR\"][\"fair\"] = dict()\n",
    "results[\"fairLR\"][\"proxy\"] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, y_train, x_control_train, x_test, y_test, x_control_test, SV):\n",
    "    x_train = ut.add_intercept(x_train)\n",
    "    x_test = ut.add_intercept(x_test)\n",
    "    apply_fairness_constraints = 1\n",
    "    apply_accuracy_constraint = 0\n",
    "    sensitive_attrs = [SV]\n",
    "    sensitive_attrs_to_cov_thresh = {SV: 0}\n",
    "    sep_constraint = 0\n",
    "    loss_function = lf._logistic_loss\n",
    "    gamma = 0\n",
    "    \n",
    "    \n",
    "    def train_test_classifier():\n",
    "        w = ut.train_model(x_train, y_train, x_control_train, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "        train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "        distances_boundary_test = np.dot(x_test, w)\n",
    "        distances_boundary_train = np.dot(x_train, w)\n",
    "        prob_test = [dt.sigmoid(x) for x in distances_boundary_test]\n",
    "        prob_train = [dt.sigmoid(x) for x in distances_boundary_train]\n",
    "        all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "        correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "        cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "        p_rule = ut.print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs[0])\t\n",
    "        # return w, p_rule, test_score\n",
    "        return prob_train, prob_test\n",
    "    return train_test_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n",
      "Protected/non-protected in +ve class: 100% / 100%\n",
      "P-rule achieved: 100%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.028\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prob_train, prob_test = model(train_X, train_y, x_control_train, test_X, test_y, x_control_test, SV)\n",
    "\n",
    "dt.save_file(dataset, num_X, fold, \"LR\", np.array(prob_train), s_train, train_y_fair, train_y_proxy, np.array(prob_test), s_test, test_y_fair, test_y_proxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"fairLR\"][\"fair\"][\"roc_auc\"] = roc_auc_score(test_y, prob_test)\n",
    "results[\"fairLR\"][\"proxy\"][\"roc_auc\"] = roc_auc_score(test_y_proxy, prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_test = (np.array(prob_test) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"fairLR\"][\"fair\"][\"eo_diff\"] = equalized_odds_difference(test_y, bool_test, sensitive_features=s_test)\n",
    "results[\"fairLR\"][\"proxy\"][\"eo_diff\"] = equalized_odds_difference(test_y_proxy, bool_test, sensitive_features=s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"fairLR\"][\"fair\"][\"f1\"] = f1_score(test_y, bool_test)\n",
    "results[\"fairLR\"][\"proxy\"][\"f1\"] = f1_score(test_y_proxy, bool_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reweight as rw\n",
    "results[\"reweigh\"][\"fair\"] = dict()\n",
    "results[\"reweigh\"][\"proxy\"] = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17457577]\n",
      "Train Accuracy 0.27037037037037037\n",
      "Train Violation 0.001003393832079147  \t\t All violations [0.001003393832079147]\n",
      "Test Accuracy 1.0\n",
      "Test Violation 0.0485714285714286  \t\t All violations [-0.0485714285714286]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob_train, prob_test = rw.model(dataset, fold, num_X=num_X, use_fair = debias, exp_num = exp_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"reweigh\"][\"fair\"][\"check_acc\"] = ut.check_accuracy(None, train_X, train_y, test_X, test_y, prob_train, prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_test = (prob_test > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"reweigh\"][\"fair\"][\"eo_diff\"] = equalized_odds_difference(test_y, bool_test, sensitive_features=s_test)\n",
    "results[\"reweigh\"][\"proxy\"][\"eo_diff\"] = equalized_odds_difference(test_y_proxy, bool_test, sensitive_features=s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"reweigh\"][\"fair\"][\"f1\"] = f1_score(test_y, bool_test)\n",
    "results[\"reweigh\"][\"proxy\"][\"f1\"] = f1_score(test_y_proxy, bool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'unmitigatedLR': {'fair': {'eo_diff': 0.1722488038277512, 'roc_auc': 0.5357142857142857, 'f1': 0.7870967741935484, 'check_acc': (0.7308641975308642, 0.67, 592, 67)}, 'proxy': {'eo_diff': 0.1722488038277512, 'roc_auc': 0.5357142857142857, 'f1': 0.7870967741935484}}, 'reduction': {'proxy': {'roc_auc': 0.5357142857142857, 'f1': 0.7870967741935484, 'check_acc': (0.7308641975308642, 0.67, 592, 67), 'eo_diff': 0.1722488038277512}, 'fair': {'roc_auc': 0.5357142857142857, 'f1': 0.7870967741935484, 'check_acc': (0.7308641975308642, 0.67, 592, 67), 'eo_diff': 0.1722488038277512}}, 'fairLR': {'fair': {'roc_auc': 0.5504761904761905, 'eo_diff': 0.0, 'f1': 0.8235294117647058}, 'proxy': {'roc_auc': 0.5504761904761905, 'eo_diff': 0.0, 'f1': 0.8235294117647058}}, 'reweigh': {'fair': {'check_acc': (0.0, 0.0, 0, 0), 'eo_diff': 0.1722488038277512, 'f1': 0.810126582278481}, 'proxy': {'eo_diff': 0.1722488038277512, 'f1': 0.810126582278481}}})\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ced59da7133df83b331c1c27c8f34cf1a7a737ef2fbfbc796b57e0b90e968204"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
